export const featuresData = [
    {
        title: "Analyse de données",
        body: `J'ai une solide expérience en programmation et en data wrangling, en manipulant des données avec des technologies comme Python, Pandas et NumPy. Mon expertise comprend l'exploration, le nettoyage, et la transformation de données complexes pour les rendre exploitables, ainsi que la visualisation de résultats via des bibliothèques telles que Matplotlib et Seaborn. J'ai mené plusieurs projets d'analyse pour extraire des insights exploitables et optimiser la prise de décision.`,
    },    
    // {
    //     title: "Modélisation Prédictive",
    //     body: `J'ai développé des modèles prédictifs en utilisant des techniques de machine learning telles que la régression, les forêts aléatoires et les réseaux de neurones. Ces modèles ont été utilisés pour des prévisions et des classifications dans des projets réels, avec une optimisation des hyperparamètres grâce à GridSearch et une évaluation de la performance à l'aide de métriques comme l'AUC-ROC et la précision.`,
    // },
    {
        title: "Ingénierie des Données",
        body: `J'ai développé des compétences approfondies en gestion de flux de données, en maîtrisant l'extraction, la transformation et le chargement (ETL) de grands volumes de données. J'ai conçu et mis en place des pipelines de données automatisés, intégrant des extractions via API, SQL et NumPy pour les opérations d'extraction, ainsi que Pandas pour le traitement des données. Mes projets m'ont également permis d'explorer des techniques avancées d'optimisation de flux et de structuration de données, facilitant ainsi les analyses en aval.`,
    },  
    {
        title: "Traitement du Langage Naturel (NLP)",
        body: `J'ai acquis des compétences solides en traitement automatique du langage (NLP), comprenant le prétraitement de textes (nettoyage, tokenisation, lemmatisation) ainsi que l’analyse de sentiments et l’extraction de caractéristiques linguistiques. J'ai également travaillé sur la classification de textes en utilisant des modèles supervisés tels que la régression logistique et SVM. Technologies : Python, NLTK, spaCy, Scikit-learn, Pandas, NumPy.`,
    }, 
    {
        title: "Vision par Ordinateur",
        body: `J'ai acquis des compétences pratiques dans le développement de modèles de vision par ordinateur en utilisant des réseaux de neurones convolutifs (CNN) et des architectures avancées comme UNet++ pour la segmentation d'images. Ces compétences ont été développées dans le cadre de projets académiques de détection d'objets et de classification d'images.`,
    },
    
    
    
];
